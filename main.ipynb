{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from INEvalidador import Validador\n",
    "from INEvalidador.conexionSQL import baseSQL\n",
    "import re\n",
    "import datetime\n",
    "import dask.dataframe as dd\n",
    "import os \n",
    "\n",
    "conexion_sql = baseSQL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que obtenga la primera variable en la validación para poder identificar qué pasa usará\n",
    "def identificar_variable(condicion: str):\n",
    "    variable = re.findall(r'^\\s*([A-Za-z_][A-Za-z\\d_]*)\\s*[<>!=]*', condicion, re.MULTILINE)\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertirlas todas las columnas de la base a mayuscula\n",
    "def columnas_a_mayuscula(tabla:str):\n",
    "    base = pd.read_feather(tabla)\n",
    "    columnas_originales = base.columns\n",
    "    columnas_nuevas = []\n",
    "    for columna in columnas_originales:\n",
    "        col = columna.upper()\n",
    "        columnas_nuevas.append(col)\n",
    "    diccionario = dict(zip(columnas_originales, columnas_nuevas))\n",
    "    base = base.rename(columns=diccionario)\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_validaciones(condiciones:str, bases:list):\n",
    "    validaciones = pd.read_excel(condiciones)\n",
    "    df1 = columnas_a_mayuscula(bases[0])\n",
    "    df2 = columnas_a_mayuscula(bases[1])\n",
    "    df3 = columnas_a_mayuscula(bases[2])\n",
    "    for validacion in list(validaciones[\"Condición o Criterio\"]):\n",
    "        # Asegurarse de que validacion sea una cadena\n",
    "        validacion_str = str(validacion)\n",
    "        var = identificar_variable(validacion_str)\n",
    "        if var in list(df1.columns):\n",
    "            validacion[\"Base_a_usar\"] = 1\n",
    "        if var in list(df2.columns):\n",
    "            validacion[\"Base_a_usar\"] = 2\n",
    "        if var in list(df3.columns):\n",
    "            validacion[\"Base_a_usar\"] = 3\n",
    "    for i in range(len(bases)):\n",
    "        validaciones[validaciones[\"Base_a_usar\"] == i].to_excel(f\"ExpresionesBase{i}.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(condiciones, bases: list=[\"Bases/Ronda1/personas.feather\",\"Bases/Ronda1/HogaresRonda1.feather\",\"Bases/Ronda2/HogaresRonda2.feather\"]):\n",
    "    conexion_sql.obtener_datos()\n",
    "    clasificar_validaciones(condiciones,bases)\n",
    "    marca_temp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    carpeta_padre = \"Inconsistencias_{}\".format(marca_temp)\n",
    "    for i in range(len(bases)):\n",
    "        validador = Validador(bases[i],f'ExpresionesBase{i}.xlsx')\n",
    "        validador.process_to_export(f'Parte{i}')\n",
    "    dfs = []\n",
    "    for i in range(len(bases)):\n",
    "        dfs.append(pd.read_excel(f'ExpresionesBase{i}.xlsx'))\n",
    "    df_exportacion = pd.concat(dfs)\n",
    "    df_exportacion.to_excel(os.path.join(carpeta_padre, f'Inconsistencias.xlsx'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"Expresiones.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertirlas todas las columnas de la base a mayuscula\n",
    "def columnas_a_mayuscula(df: pd.DataFrame):\n",
    "    columnas_originales = df.columns\n",
    "    columnas_nuevas = []\n",
    "    for columna in columnas_originales:\n",
    "        col = columna.upper()\n",
    "        columnas_nuevas.append(col)\n",
    "    diccionario = dict(zip(columnas_originales, columnas_nuevas))\n",
    "    df = df.rename(columns=diccionario)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Diccionario para almacenar los nombres de los archivos y las columnas\n",
    "columnas_por_archivo = {}\n",
    "\n",
    "# Directorio donde se encuentran los archivos Feather\n",
    "directorio = 'db'\n",
    "\n",
    "# Recorre todos los archivos en el directorio especificado\n",
    "for archivo in os.listdir(directorio):\n",
    "    if archivo.endswith('.feather'):  # Verifica si el archivo es un archivo Feather\n",
    "        ruta_completa = os.path.join(directorio, archivo)\n",
    "        try:\n",
    "            # Lee el archivo Feather\n",
    "            df = pd.read_feather(ruta_completa)\n",
    "            df = columnas_a_mayuscula(df)\n",
    "            \n",
    "            # Obtiene las columnas del DataFrame\n",
    "            columnas = df.columns.tolist()\n",
    "\n",
    "            \n",
    "            # Agrega el nombre del archivo y las columnas al diccionario\n",
    "            columnas_por_archivo[archivo] = columnas\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer el archivo {archivo}: {str(e)}\")\n",
    "\n",
    "# Muestra el diccionario con los nombres de los archivos y las columnas\n",
    "columnas_por_archivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['P16A01', 'P17A06B']\n",
    "\n",
    "df_a_unir = [conexion_sql.base_df.get(conexion_sql.base_col.get(var)) for var in variables]\n",
    "df_base = df_a_unir[0]\n",
    "for df in df_a_unir[1:]:\n",
    "    df_base = pd.merge(df_base, df, on='LEVEL-1-ID', how='outer')\n",
    "df_base[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexion_sql.base_df['level-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mchinchilla\\Documents\\GitHub\\INE_ValidacionENCOVI\\INEvalidador\\conexionSQL.py:57: FutureWarning: Passing 'suffixes' which cause duplicate columns {'INDEX_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_base = pd.merge(df_base, df, on='LEVEL-1-ID', how='inner')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX_x</th>\n",
       "      <th>LEVEL-1-ID</th>\n",
       "      <th>CASE-ID</th>\n",
       "      <th>DEPTO_SR</th>\n",
       "      <th>MUPIO_SR</th>\n",
       "      <th>SECTOR_SR</th>\n",
       "      <th>ESTRUCTURA_SR</th>\n",
       "      <th>VIVIENDA_SR</th>\n",
       "      <th>HOGAR_SR</th>\n",
       "      <th>ENCUESTADOR_SR</th>\n",
       "      <th>...</th>\n",
       "      <th>P12A14B</th>\n",
       "      <th>P12A14C</th>\n",
       "      <th>P12A14D</th>\n",
       "      <th>P12A14E</th>\n",
       "      <th>P12A14F</th>\n",
       "      <th>P12A14G</th>\n",
       "      <th>P12A14H</th>\n",
       "      <th>P12A14I</th>\n",
       "      <th>P12A14J</th>\n",
       "      <th>P12A14JA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 730 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [INDEX_x, LEVEL-1-ID, CASE-ID, DEPTO_SR, MUPIO_SR, SECTOR_SR, ESTRUCTURA_SR, VIVIENDA_SR, HOGAR_SR, ENCUESTADOR_SR, SUPERVISOR_SR, INDEX_y, AGROPECA-ID, P16A01, P16A02, P16A02B, INDEX_x, PRESTAMOSA2-ID, OCC_x, P17A06B, P17A07, P17A08, P17A09A, P17A09B, P17A10A, P17A10B, P17A11A, P17A11B, P17A12A, P17A12B, P17A13A, P17A13B, P17A14A, P17A14B, P17A14C, P17A15A, P17A15B, P17A16, P17A17A, P17A17B, P17A18, P17A19A, P17A19B, P17A19C, P17A20Z, INDEX_y, PERSONAS-ID, OCC_y, ID_PERSONA, NPERSONA, APERSONA, NSEXO, NEDAD, PPA04A, PPA04B, PPA04C, PPERSONA, NPARENTESCO, PPA06, PPA07A, PPA07B, PPA07C, PPA07D, PPA07E, PPA07F, PPA08, PPA09A, PPA09B, PPA10, PPA11A, PPA11B, PPA11C, CAPI_IIIB, P03B01, P03B02, P03B03, P03B04, P03C01, P03C01A, P03C02, P03C02A, CAPI_IV, P04A01A, P04A01B, P04A02, P04A03, P04A04A, P04A04B, P04A05, P04A06, P04A07, P04A08, P04A09, P04A10, P04A11, P04A12, P04A13, P04A13A, CAPI_V, P05A01, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 730 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from INEvalidador.validador import Validador\n",
    "p = Validador()\n",
    "p.sql.df_para_condicion(['P16A01', 'P17A06B'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
